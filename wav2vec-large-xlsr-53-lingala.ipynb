{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f88221ce",
   "metadata": {},
   "source": [
    "# Finetune wav2vec2 for Lingala\n",
    "This notebook is adapted from Fine-tuning Wav2Vec2 for Turkish ASR to train Lingala ASR using our own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a878689",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f87c00",
   "metadata": {},
   "source": [
    "# installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3ff79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install datasets==1.11.0\n",
    "!{sys.executable} -m pip install transformers==4.9.1\n",
    "!{sys.executable} -m pip install jiwer\n",
    "!{sys.executable} -m pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78633a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import zipfile\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ubuntu/LingalaAudio/pyLingala-master/data/train.csv', newline='',encoding='UTF-8') as f:\n",
    "      reader = csv.reader(f)\n",
    "      data = list(reader)\n",
    "      train_data = [data[i] for i in range(len(data)) if i!=0]\n",
    "\n",
    "with open('/home/ubuntu/LingalaAudio/pyLingala-master/data/test.csv', newline='',encoding='UTF-8') as f:\n",
    "      reader = csv.reader(f)\n",
    "      data = list(reader)\n",
    "      t_data = [data[i] for i in range(len(data)) if i!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d1496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get valid indices\n",
    "import random\n",
    "random.seed(42) #this seed was used specifically to compare with Okwugbe model\n",
    "\n",
    "\n",
    "\n",
    "v = 300 #200 samples for valid. Change as you want\n",
    "test_list = [i for i in range(len(t_data))]\n",
    "valid_indices = random.choices(test_list, k=v)\n",
    "\n",
    "\n",
    "test_data = [t_data[i] for i in range(len(t_data)) if i not in valid_indices]\n",
    "valid_data = [t_data[i] for i in range(len(t_data)) if i in valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef3f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(d):\n",
    "  utterance = d[2]\n",
    "  wav_path =d[0]\n",
    "  wav_path = wav_path.replace(\"/home/ubuntu/organised_recording\",\"/home/ubuntu/LingalaAudio/pyLingala-master\")\n",
    "  return {\n",
    "      \"path\": wav_path,\n",
    "      \"sentence\": utterance\n",
    "  }\n",
    "\n",
    "train_json = [create_json_file(i) for i in train_data]\n",
    "test_json = [create_json_file(i) for i in test_data]\n",
    "valid_json = [create_json_file(i) for i in valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec44bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a425dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make folder to store files\n",
    "\n",
    "\n",
    "train_path = '/home/ubuntu/model_output/lingala_xlsr4/train'\n",
    "test_path = '/home/ubuntu/model_output/lingala_xlsr4/test'\n",
    "valid_path = '/home/ubuntu/model_output/lingala_xlsr4/valid'\n",
    "\n",
    "if not os.path.isdir(train_path):\n",
    "  print(\"Creating paths\")\n",
    "  os.makedirs(train_path)\n",
    "  os.makedirs(test_path)\n",
    "  os.makedirs(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbf15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#for train\n",
    "for i, sample in enumerate(train_json):\n",
    "  file_path = os.path.join(train_path,'train_lingala_{}.json'.format(i))\n",
    "  with open(file_path, 'w') as outfile:\n",
    "    json.dump(sample, outfile)\n",
    "\n",
    "#for test\n",
    "for i, sample in enumerate(test_json):\n",
    "  file_path = os.path.join(test_path,'test_lingala_{}.json'.format(i))\n",
    "  with open(file_path, 'w') as outfile:\n",
    "    json.dump(sample, outfile)\n",
    "\n",
    "#for valid\n",
    "for i, sample in enumerate(valid_json):\n",
    "  file_path = os.path.join(valid_path,'valid_lingala_{}.json'.format(i))\n",
    "  with open(file_path, 'w') as outfile:\n",
    "    json.dump(sample, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "\n",
    "#run the second time after the error\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "#for train\n",
    "for root, dirs, files in os.walk(train_path):\n",
    "  lingala_train = load_dataset(\"json\", data_files=[os.path.join(root,i) for i in files],split=\"train\")\n",
    "\n",
    "#for test\n",
    "for root, dirs, files in os.walk(test_path):\n",
    "  lingala_test = load_dataset(\"json\", data_files=[os.path.join(root,i) for i in files],split=\"train\")\n",
    "\n",
    "#for valid\n",
    "for root, dirs, files in os.walk(valid_path):\n",
    "  lingala_valid = load_dataset(\"json\", data_files=[os.path.join(root,i) for i in files],split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47daaa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingala_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60167596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    print(len(dataset))\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430379fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_elements(lingala_test, num_examples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6610370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingala_train = lingala_train.map(remove_special_characters)\n",
    "lingala_test = lingala_test.map(remove_special_characters)\n",
    "lingala_valid = lingala_valid.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f6a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_elements(lingala_train.remove_columns([\"path\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "  all_text = \" \".join(batch[\"sentence\"])\n",
    "  vocab = list(set(all_text))\n",
    "  return {\"vocab\": [vocab], \"all_text\": [all_text]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969837d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_train = lingala_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=lingala_train.column_names)\n",
    "vocab_test = lingala_test.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=lingala_test.column_names)\n",
    "vocab_valid = lingala_valid.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=lingala_valid.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3daa191",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]) | set(vocab_valid[\"vocab\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dcc48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39211bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/home/ubuntu/model_output/lingala_xlsr4/vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8269fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"/home/ubuntu/model_output/lingala_xlsr4/vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fecb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc0d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are running this Colab for the first time and have not saved the processor, uncomment code below\n",
    "processor.save_pretrained(\"/home/ubuntu/model_output/lingala_xlsr4/wav2vec2-large-xlsr-lingala\")\n",
    "\n",
    "#To load trained processor\n",
    "model_dir='/home/ubuntu/model_output/lingala_xlsr4/wav2vec2-large-xlsr-lingala'\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingala_train[197]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe903d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5894dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = speech_array[0].numpy()\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"sentence\"]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingala_train = lingala_train.map(speech_file_to_array_fn, remove_columns=lingala_train.column_names)\n",
    "lingala_test = lingala_test.map(speech_file_to_array_fn, remove_columns=lingala_test.column_names)\n",
    "lingala_valid = lingala_valid.map(speech_file_to_array_fn, remove_columns=lingala_valid.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79548632",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingala_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95932a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(lingala_train)-1)\n",
    "\n",
    "ipd.Audio(data=np.asarray(lingala_train[rand_int][\"speech\"]), autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand_int = random.randint(0, len(fon_train)-1)\n",
    "\n",
    "print(\"Target text:\", lingala_train[rand_int][\"target_text\"])\n",
    "print(\"Input array shape:\", np.asarray(lingala_train[rand_int][\"speech\"]).shape)\n",
    "print(\"Sampling rate:\", lingala_train[rand_int][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58162942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ff0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "lingala_train = lingala_train.map(prepare_dataset, remove_columns=lingala_train.column_names, batch_size=8, num_proc=4, batched=True)\n",
    "lingala_test = lingala_test.map(prepare_dataset, remove_columns=lingala_test.column_names, batch_size=8, num_proc=4, batched=True)\n",
    "lingala_valid = lingala_valid.map(prepare_dataset, remove_columns=lingala_valid.column_names, batch_size=8, num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fdecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe746624",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0973d6",
   "metadata": {},
   "source": [
    "## Metric\n",
    "We use word error rate with space as word boundary. We also use character error rate without word boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05d1e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import (\n",
    "    load_dataset, \n",
    "    load_from_disk,\n",
    "    load_metric,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "778b9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f514c277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_metric.compute(predictions=['สวัสดี ค่า ทุก โคน'],references=['สวัสดี ค่ะ ทุก คน'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650d5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1349465",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_metric = load_metric('cer/cer.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44b70119",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "number of ground truth inputs (4) and hypothesis inputs (3) must match.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcer_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maab\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maaac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.8/site-packages/datasets/metric.py:453\u001b[0m, in \u001b[0;36mMetric.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {input_name: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[input_name] \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures}\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[0;32m--> 453\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_writer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/metrics/cer/dd62d9d14a0b59483ced16be0b946126146a67ae4624b676d7f7147dc25e88f5/cer.py:82\u001b[0m, in \u001b[0;36mCER._compute\u001b[0;34m(self, predictions, references, chunk_size)\u001b[0m\n\u001b[1;32m     80\u001b[0m     preds \u001b[38;5;241m=\u001b[39m [char \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m predictions \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(seq)]\n\u001b[1;32m     81\u001b[0m     refs \u001b[38;5;241m=\u001b[39m [char \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m references \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(seq)]\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjiwer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     84\u001b[0m end \u001b[38;5;241m=\u001b[39m chunk_size\n",
      "File \u001b[0;32m~/pyenv/lib/python3.8/site-packages/jiwer/measures.py:71\u001b[0m, in \u001b[0;36mwer\u001b[0;34m(truth, hypothesis, truth_transform, hypothesis_transform)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwer\u001b[39m(\n\u001b[1;32m     58\u001b[0m     truth: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m     59\u001b[0m     hypothesis: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m     60\u001b[0m     truth_transform: Union[tr\u001b[38;5;241m.\u001b[39mCompose, tr\u001b[38;5;241m.\u001b[39mAbstractTransform] \u001b[38;5;241m=\u001b[39m wer_default,\n\u001b[1;32m     61\u001b[0m     hypothesis_transform: Union[tr\u001b[38;5;241m.\u001b[39mCompose, tr\u001b[38;5;241m.\u001b[39mAbstractTransform] \u001b[38;5;241m=\u001b[39m wer_default,\n\u001b[1;32m     62\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    Calculate word error rate (WER) between a set of ground-truth sentences and\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    a set of hypothesis sentences.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m    :return: WER as a floating point number\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     measures \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_measures\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruth_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis_transform\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m measures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/pyenv/lib/python3.8/site-packages/jiwer/measures.py:182\u001b[0m, in \u001b[0;36mcompute_measures\u001b[0;34m(truth, hypothesis, truth_transform, hypothesis_transform)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone or more groundtruths are empty strings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Preprocess truth and hypothesis\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m truth, hypothesis \u001b[38;5;241m=\u001b[39m \u001b[43m_preprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruth_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis_transform\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# keep track of total hits, substitutions, deletions and insertions\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# across all input sentences\u001b[39;00m\n\u001b[1;32m    188\u001b[0m H, S, D, I \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/pyenv/lib/python3.8/site-packages/jiwer/measures.py:300\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(truth, hypothesis, truth_transform, hypothesis_transform)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# raise an error if the ground truth is empty or the output\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# is not a list of list of strings\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(transformed_truth) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(transformed_hypothesis):\n\u001b[0;32m--> 300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of ground truth inputs (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) and hypothesis inputs (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) must match.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    302\u001b[0m             \u001b[38;5;28mlen\u001b[39m(transformed_truth), \u001b[38;5;28mlen\u001b[39m(transformed_hypothesis)\n\u001b[1;32m    303\u001b[0m         )\n\u001b[1;32m    304\u001b[0m     )\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_list_of_list_of_strings(transformed_truth, require_non_empty_lists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruth should be a list of list of strings after transform which are non-empty\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: number of ground truth inputs (4) and hypothesis inputs (3) must match."
     ]
    }
   ],
   "source": [
    "cer_metric.compute(predictions=['aab'],references=['aaac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412197e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce0644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca832f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aed38e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
